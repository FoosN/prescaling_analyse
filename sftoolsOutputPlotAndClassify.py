#!/usr/bin/python2.7
# -*-coding:Utf-8 -*

"""
Copyright (c) 2014, Nicolas Foos
All rights reserved.

Redistribution and use in source and binary forms, with or without modification, 
are permitted provided that the following conditions are met:
1. Redistributions of source code must retain the above copyright notice, this
list of conditions and the following disclaimer.

2. Redistributions in binary form must reproduce the above copyright notice,
this list of conditions and the following disclaimer in the documentation and/
or other materials provided with the distribution.

3. Neither the name of the copyright holder nor the names of its contributors 
may be used to endorse or promote products derived from this software without 
specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" 
AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE 
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE 
ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE 
LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR 
CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF 
SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS 
INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN 
CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) 
ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE 
POSSIBILITY OF SUCH DAMAGE."""

"""Progs to plot table of correlation from SFTOOLS ccp4
and to create a hierarchical clustering of the datasets """
import sys
import os
import time
import numpy as np
import scipy.cluster.hierarchy as hac
import re
import matplotlib.pyplot as pp
#to modify at the end of the devpt
#sys.path.append("/progs/progsDev/gitRepo/prescaling_analyse")
#sys.path.append("/data/bioxsoft/bin")

def interactiv_path():
    global maninput_files    
    maninput_files =[]
    global filetype
    maninput_files = []
    for arg in sys.argv[1:]:
        try:
            if os.path.isfile(arg):
                if "!Generated by XSCALE" in open(arg).read():
                    maninput_files.append(arg)
                    filetype = "XSCALE"
                elif "!Generated by CORRECT" in open(arg).read():
                    maninput_files.append(arg)
                    filetype = "XDS_ASCII"
        except: 
            pass
    return maninput_files
    print maninput_files
    return filetype
    print filetype

def determine_reso(filetype, maninput_files):
    resoTable = []
    resolution = []
    if filetype == "XSCALE":
        listeofFile = os.listdir("./")
        for i in listeofFile:
            if i == "XSCALE.LP":
                with open(i) as entry :
                    for lines in entry :
                        if re.search(r"INCLUDE_RESOLUTION_RANGE=", lines):
                            resoTable.append(lines)
                    for i in resoTable:
                        resolution.append(i[-7:-1])
                    resoCut = round(float(max(resolution)), 2)
    if filetype == "XDS_ASCII":
        #this is relevant only if the run of XDS used good parameters
    # as it is in by xdsme for example
        correctlp = [i.replace('XDS_ASCII.HKL', 'CORRECT.LP') for i in maninput_files]
        for i in correctlp :
            with open(i) as entry:
                for lines in entry :
                    if re.search(r"INCLUDE_RESOLUTION_RANGE=", lines):
                        resoTable.append(lines)
                for i in resoTable:
                    resolution.append(i[-7:-1])
                resoCut = round(float(max(resolution)), 2)
    return resoCut

def export_conv_table(truePath):
    towrite = []    
    for entry in truePath:
        towrite.append("number "+str(truePath.index(entry)+1)+" is "+entry+" \n")
    return towrite
        
def findPath_of_originalFiles(inputfiles):
    """find the path to the HKL files from XSCALE.HKL"""
    #inputfiles is a path to XSCALE.HKL output file    
    for arg in inputfiles:
        try:
            with open(arg) as input_file :
                global inputFile                    
                inputFile = input_file.readlines()
                for lines in inputFile :
                    if re.search(r"!Generated by XSCALE", lines):
#            if "!Generated by XSCALE" in open(arg).read():
                        create = True
#                inputFile = open(arg)
            if create == True:
                print "XSCALE.HKL is take in count"
                path = []
                truePath = []
                for lines in inputFile :
                    if re.search(r"INPUT_FILE", lines):
                        path.append(lines)
                for i in path:
                    startIndex = i.index("FILE=")+5
                    endIndex = i.index(".HKL")+4
                    truePath.append(i[startIndex:endIndex]) 
                return truePath                
                return create
                return inputFile
                return arg
                    
        except:
            print ("it's not XSCALE.HKL or it's corrupted")
            exit(0) 
#        if create == True:
#            print ("XSCALE OK")
#            path = []
#            truePath = []
#            for lines in inputFile :
#                if re.search(r"INPUT_FILE", lines):
#                    path.append(lines)
#            for i in path:
#                startIndex = i.index("FILE=")+5
#                endIndex = i.index(".HKL")+4
#                truePath.append(i[startIndex:endIndex]) 
#                return truePath
#truePath is a list of path which can be given to the function of conversion
#in mtz

def convert_in_mtz(i, j):
#    j = 0
#    mtzPath=[]
#    for i in truePath:
    os.mkdir("./dataset"+str(j+1))
    os.chdir("./dataset"+str(j+1))
#    nPath = "./conv"+str(j)+"/ccp4/"+str(mtz)
    os.system("xdsconv.py ../"+i+" -a ccp4") 
    j+=1        
    os.chdir("../")
    
def search_mtz_file(numberJ):
    i = 1
    ready = True
    while ready is False:
        try :      
            listeofFile = os.listdir("./dataset"+str(numberJ)+"/ccp4/")
        except :
            ready = False
            time.sleep(5)
    while i <= numberJ :    
        listeofFile = os.listdir("./dataset"+str(i)+"/ccp4/")
        mtz = [entry for entry in listeofFile if ".mtz" in entry]  
        nPath = "./dataset"+str(i)+"/ccp4/"+str(mtz[0])
        mtzPath.append(nPath)
        i+=1  
    return mtzPath
#        os.chdir("../")
#    return mtzPath
        #mtzPath is the list of .mtz Path for use with SFTOOLS
        
# function to create different .HKL based on the XSCALE.HKL 
# this function will split the XSCALE in different split.HKL file 
        
def parse_XSCALE_dataset(maninput_files):
    for i in maninput_files:
        with open(i) as original :
            info = []
            for line in original:
                if "!FORMAT=XDS_ASCII" in line:
                    info.append(line)
                if "!SPACE_GROUP_NUMBER=" in line:
                    info.append(line)
                if "!UNIT_CELL_CONSTANTS=" in line:
                    info.append(line)
                if "!ITEM" in line:
                    info.append(line)
                if "X-RAY_WAVELENGTH=" in line:
                    info.append(line)
                if "!END_OF_HEADER" in line:
                    info.append(line)
        with open(i) as original :
            number_of_dataset=0
            for line in original:
                if "X-RAY_WAVELENGTH=" in line:
                     number_of_dataset +=1
            i = 1
            dataset ={}
            while i <= number_of_dataset:
                dataset[i]=info
                i+=1
            ks= dataset.keys()
            print ks
        with open("./XSCALE.HKL") as original :
            for line in original:
               if "!END_OF_HEADER" in line:
                   try:
                        while (original.next()[-2]) != "!END_OF_DATA" :
                            reflec = original.next()
                            dataset[int(reflec[-2])].append(reflec)
                   except :
                       pass
    return dataset

def parse_XSCALE_dataset_fast(maninput_files):
    for i in maninput_files:
        with open(i) as original :
            nb=1
            for line in original:
                if "X-RAY_WAVELENGTH=" in line:
                     nb +=1
        os.system("head -100 "+i+"   | grep \! > H")
        os.system("tail  -10 "+i+"   | grep \! > T")
        j = 1
        k = 1
        while j < nb:
            os.system('grep " "'+str(j)+'\$ '+i+' > '+str(j))
            os.system('cat H '+str(j)+' T > '+'postscale'+str(j)+'.HKL')
            j+=1
    while k < nb :
        os.system("rm "+ str(k))
        k +=1
    os.system("rm H T")
        
        

#function to write text file, this file will be use by sftools (path should be mtzPath) 
def writing_list_in_file(path1, file2write, filetype):
    g = 0
    if filetype == "sftoolsINP":
        command = file2write.__iter__()
        for i in file2write: 
           outputfile = open(os.path.join(path1, "SFTOOLS.INP"+str(g)), 'w')
           outputfile.write(command.next())
           g += 1
    elif filetype == "XDS_ASCII":
        outputfile = open(os.path.join(path1, "conversion_table"), 'w')
        if type(file2write) is dict:        
            for i in file2write:                
                outputfile.write(file2write[file2write.index(i)])
        else :
            for i in file2write:
                outputfile.write(i)
    elif filetype == "XSCALE":
        for key in file2write:
            outputfile = open(os.path.join("./", "postscale"+str(g))+".HKL", 'w')
            for i in file2write[key]:
                toprint = i
                outputfile.write(toprint) 
            g +=1
        
#function to list the number of file entry in XSCALE.LP
def find_list(filetype, path):
    towrite = []
    if filetype == "XSCALE":
        for i in path:
            towrite.append("file name "+str(path.index(i))+" is the number "+str(path.index(i)+1)+" in XSCALE.LP or HKL \n")
    return towrite
        
#function to list and execute the INP of SFTOOLS 
def list_and_execute_SFTOOLS(path):
    """this function check the name and number of files present for SFTOOLS
    and run SFTOOLS with each one of them"""
    sftoolsINP = os.listdir(path)
    filteredINP = [i for i in sftoolsINP if "SFTOOLS" in i]
#execute of sftools    
    for i in filteredINP:
        os.system("sftools <"+str(i)+">SFTOOLS.out"+str(filteredINP.index(i)))
    

#mtz1 and mtz2 come from xdsconv.py which must run with all the XDS_ASCII from the XSCALE.INP
def sftools_input(mtzList, resoCut):
    """ this function take mtz from the list and create new list with entry
    to create input file for sftools"""
    i = 0
    j = i+1
    Job = []
    vs_read = []
    vs = []
    while j < len(mtzList):
        while i <= len(mtzList):
            if j > i and j != i :
                Job.append("READ\n" + str(mtzList[j]) + "\n" + "READ\n" + str(mtzList[i]) + "\n\
CHECKHKL\nSELECT RESOL > "+str(resoCut)+"\n"+"CORREL\nCOLUMN 4 10\nSTOP\ny\nEOF\n")
                vs_read.append("dataset "+str(j+1)+"VS dataset "+str(i+1))
                vs.append([int(j), int(i)])
            i+=1
        j+=1
        i = 0
    job_vs = {}
    job_vs["job"]= Job
    job_vs["vs_read"]= vs_read
    job_vs["vs"]= vs
    #return Job
   # return vs
    return job_vs
#    sftools = subprocess.Popen(["sftools <"+ fileInp], 0, stderr=subprocess.STDOUT, stdout=subprocess.PIPE, shell=True)
#    print sftools
    
def grab_sftools_out(YorN):
    #idea : pick multiple sftools output, put them in list,
#from this list, read object (sftools.log) and read line in the sftools.log
#extract table from this file.
#if i use popen to run sftools, it would be smart to populate this list with the object create for each run of sftools
    filePresent = os.listdir("./")
    filesOut = [files for files in filePresent if "SFTOOLS.out" in files]
    tables = []
    overallStats = []
    for entry in filesOut:
        with open(entry) as f1:
            lines = f1.readlines()
            for line in lines :
                if "NSHELL  DMIN    DMAX    RFACT   CORREL    <F1>    <F2>    NREF " in line :
                    startline = lines.index(line)+1
                if "OVERALL STATISTICS" in line:
                    endline = lines.index(line)
                    overallStats.append(line)
            tables.append(lines[startline:endline])
    if YorN == "y":    
        return tables
    return overallStats
    
def parse_and_prepare(overallStats):
    newstats = []    
    for i in overallStats:
        newstats.append(i.split()[3])
    distance = [round(1-float(i),2) for i in newstats]
    #distance is 1 - overall anomalous correlation calculate by sftools
    return distance
    

def get_distance(mtzlist, job_vs):
    n = len(mtzlist)
    dist_mat = np.zeros([n,n])
    for i in job_vs["distance"]:
        dist_mat[job_vs["vs"][job_vs["distance"].index(i)][0], job_vs["vs"][job_vs["distance"].index(i)][1]] = i
    return dist_mat

def statsByresol(tables):
    dictTable = {}
    statDic = {}
    for i in tables:
        lineclean = ''.join(i)
        lineclean = lineclean.replace('$$', '')
        lineclean = lineclean.replace('\n', '')
        clean = lineclean.split()
        dictTable[tables.index(i)]= clean
    for key in dictTable:
        n1 = 8
        n2 = np.size(dictTable[key])/n1
        tablei = np.array(dictTable[key])
        tablei.resize(n2, n1)
        dictTable[key] = tablei
    for key in dictTable:
        x = []
        y = []
        for i in dictTable[key]:
            x.append(i[1])
            y.append(i[4])
            statDic[str(key)+"_x"] = x
            statDic[str(key)+"_y"] = y
    return statDic
    
def plotData(statDic, job_vs):
        pp.clf()
        x = statDic["0_x"]        
        legends = []
        temp = []
        for i in statDic.keys():
            if '_y' in i :
                temp.append(i)
                temp.sort()
        for j in temp:
            pp.xlim(float(x[1]), float(x[-1]))
            pp.plot(x, statDic[str(j)])
            legends.append(job_vs["vs"][temp.index(j)]) #is to give correspondence between data Y and the correlation vs
#        ticks = np.arange(int(min(datasets[i-1].table[colXnmbr])), int(max(datasets[i-1].table[colXnmbr])), 1)
#        ticks = ticks.tolist()
#        ticks.reverse()
#        index2remove = [-2, -1]
#        for index in index2remove:
#            del ticks[index]
#        ticks.append(round(min(datasets[i-1].table[colXnmbr]),1))
#        labels = ticks
#        print ticks
#        print type(ticks)
#        pp.xticks(ticks, labels)       
            pp.legend(legends, loc= 'best', prop={'size':8})
            pp.xlabel("Resolution Angstrom")
            pp.ylabel("anomalous_correlation")
            pp.savefig(os.path.join("./correlationAno1to1.png"),
            dpi=300, facecolor='w', edgecolor='w', orientation='landscape')
            pp.figure()
            pp.plot()
            pp.close()            
         
        
    


####################take the decision of how to re run XSCALE and generate XSCALE.INP


    


   
#execute scripts:
initial = interactiv_path()
path = "./"
if filetype == "XDS_ASCII":
   truePath = maninput_files
   towrite = export_conv_table(truePath)
   print "this is towrite ", towrite
   writing_list_in_file(path,towrite,filetype)
   print "this is truePath " 
   print (truePath)
#elif filetype == "XSCALE":
#   truePath = findPath_of_originalFiles(maninput_files)
#   print "this is truePath "
#   print (truePath)
elif filetype == "XSCALE":
    #towrite = parse_XSCALE_dataset(maninput_files)
    #writing_list_in_file(path,towrite,filetype) 
    parse_XSCALE_dataset_fast(maninput_files)   
    listeofFile = os.listdir("./")
    truePath = [entry for entry in listeofFile if "postscale" in entry]
    print (truePath)



mtzPath = []
j = 0
for i in truePath :
    convert_in_mtz(i, j)
    j+=1
numberJ = len(truePath)
mtzPath = search_mtz_file(numberJ)
if filetype == "XSCALE":
    towrite = find_list("XSCALE", mtzPath)
    writing_list_in_file(path, towrite ,"XDS_ASCII")    
print "this is mtzlist "+str(mtzPath)
resocut = raw_input ('set the resolution cut-off the default will be :')# \
#+ str(resolution) +' :')
if resocut == '':
    resoCut = determine_reso(filetype, truePath)
else :
    resoCut = resocut
job_vs = sftools_input(mtzPath, resoCut)
job_vs["truepath"]= truePath #keep the truePath in object for future function
writing_list_in_file(path, job_vs["job"], "sftoolsINP")
list_and_execute_SFTOOLS(path)
overallStats = grab_sftools_out("N")
byresoStats = grab_sftools_out("y")
statDic = statsByresol(byresoStats)
plotData(statDic, job_vs)
job_vs["distance"] = parse_and_prepare(overallStats)
print "ceci est job distance :"+ str(job_vs["distance"])
matrix_dis = get_distance(mtzPath, job_vs)
print "ceci est la matrice de distance :"+ "\n" + str(matrix_dis)
pp.clf()
hac.dendrogram(hac.linkage(matrix_dis, 'complete'), color_threshold=0.15)
pp.title('Overall anomalous dissimilarity')
pp.savefig("dendro_dissim_Ano.png", dpi=150)
